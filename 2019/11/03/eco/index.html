<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0" />

    <!--Description-->
    
        <meta name="description" content="IntroductionTrying to build a cognitive map from First-Person videos that can be used to understand novel but similar environments, which will benefit">
    

    <!--Author-->
    
        <meta name="author" content="Xuefei Li">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Egocentric Cognitive Mapping"/>
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="XuefeiLi(李雪霏)"/>

    <!--Page Cover-->
    
        <meta property="og:image" content=""/>
    

    <!-- Title -->
    
    <title>Egocentric Cognitive Mapping - XuefeiLi(李雪霏)</title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/reset.css">

    
<link rel="stylesheet" href="/css/main.css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    


    <!--Favicon-->
    
        <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/assets/favicon.ico" type="image/x-icon">
    

<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Menu -->
<!-- Navigation -->
<header>
    <div class="logo">
        <a href="/">XuefeiLi(李雪霏)</a>
    </div><!-- end logo -->

    <div id="menu_icon"></div>
    <nav>
        <ul>
            
            <li>
                <a href="/">Home</a>
            </li>
            
            <li>
                <a href="/archives">Archives</a>
            </li>
            
        </ul>
    </nav><!-- end navigation menu -->

</header><!-- end header -->


<!-- Main Content -->
<section class="main clearfix">

    <section class="top" style="background: url('/assets/header.jpeg');">
        <div class="wrapper content_header clearfix">
            

<div class="work_nav">

    <ul class="btn clearfix">
        
        <li><a href="/2019/11/04/Mimic-Robot/" class="previous" data-title="Mimic Robot"></a></li>
        
        <li><a href="/" class="grid" data-title="Portfolio"></a></li>
        
        <li><a href="/2019/11/02/Food-web-visualization/" class="next" data-title="Food web visualiz..."></a></li>
        
    </ul>

</div><!-- end work_nav -->
            <h1 class="title">Egocentric Cognitive Mapping</h1>
        </div>
    </section><!-- end top -->

    <section class="wrapper">
        <div class="content">

            <!-- Gallery -->
            

            <!-- Content -->
            <h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Trying to build a cognitive map from First-Person videos that can be used to understand <em>novel</em> but <em>similar</em> environments, which will benefit visually-impaired people. Instructed by Prof. Hyun Soo Park and his group at UMN.</p>
<p><img src="/assets/eco/eco.gif" alt="eco"></p>
<p><a href="https://youtu.be/3wsUlLbtzko" target="_blank" rel="noopener">Demo</a>: Groccery store data annotation with ECO;<br><a href="https://github.com/semantic-localization" target="_blank" rel="noopener">Code</a></p>
<p>Local Egocentric Maps</p>
<p><img src="/assets/eco/eco1.jpg" alt="eco1">)<img src="/assets/eco/eco2.jpg" alt="eco2"></p>
<p>Local Egocentric Maps</p>
<ol>
<li>Frontalization via Homography</li>
</ol>
<p><img src="/assets/eco/eco3.png" alt="eco3"></p>
<ol start="2">
<li>Rescaling for canonical depth viewpoint</li>
</ol>
<p><img src="/assets/eco/eco4.png" alt="eco4"></p>
<p>My work mainly focus on the egocentric recognition of sections in supermarket with a novel interface by leveraging scene geometry and reconstructed camera motion.</p>
<ol>
<li><p>Undistort the image using camera intrinsic parameters</p>
<p>Assume that sections are aligned with the three principal orthogonal directions of the scene.</p>
</li>
<li><p>Calculate three mutually orthogonal vanishing points. We manually select points $vp_x$ and $vp_y$ in X and Y directions in camera coordinate system.<br>Consider the 3D point where the X axis (in camera coordinates) meets the projective line corresponding to $vp_x$,  let this point be $Xp$. Using K for the camera intrinsic parameters, R and C for pose, we must have</p>
</li>
</ol>
<p>$$\lambda v p_x=KR(X_p-C)\Rightarrow X_p-C=\lambda R^T K^{-1} v p_x$$</p>
<p>The X axis direction in 3D is thus given by unit $(Xp−C)$. Similarly, the Y direction and the gravity vector is obtained as the cross product of the two. We observe that using the cross product gives more stable gravity vector compared to simply using the output from the algorithm.</p>
<p><img src="/assets/eco/eco5.png" alt="eco5"></p>
<ol start="3">
<li><p>Triangulate an origin point in 3D using pixel correspondence between two images. </p>
</li>
<li><p>Using the origin and axes, construct a bounding box in 3D that is projected onto the image.</p>
</li>
<li><p>Keyboard input to the interface can be used to move each of the faces of the box in the normal direction.</p>
</li>
</ol>
<p><img src="/assets/eco/eco6.png" alt="eco6"></p>
<ol start="6">
<li>propagate labels to the box.</li>
</ol>
<p><img src="/assets/eco/eco7.png" alt="eco7"></p>


            <!-- Tags -->
            


<div class="tags">
    <a href="/tags/Computer-Vision-3D-reconstruction/">Computer Vision, 3D reconstruction</a>
</div>



            <!-- Comments -->
            <div>
                




            </div>
        </div><!-- end content -->
    </section>
</section><!-- end main -->

<!-- After footer scripts -->

<!-- jQuery -->

<script src="/js/jquery.js"></script>


<!-- Custom Code -->

<script src="/js/main.js"></script>


<!-- Gallery -->
<script src="//cdn.rawgit.com/noelboss/featherlight/1.3.5/release/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>